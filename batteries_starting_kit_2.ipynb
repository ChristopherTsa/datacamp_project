{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <a href=\"https://www.dataia.eu/\">\n",
    "        <img border=\"0\" src=\"https://github.com/ramp-kits/lwfa/raw/main/img/DATAIA-h.png\" width=\"90%\"></a>\n",
    "</div>\n",
    "\n",
    "# RAMP on eVTOL Battery Degradation Prediction\n",
    "\n",
    "<i>Data Science Challenge</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Electric Vertical Takeoff and Landing (eVTOL) Batteries\n",
    "\n",
    "Electric Vertical Takeoff and Landing (eVTOL) vehicles represent the forefront of urban air mobility. These aircraft rely heavily on high-performance batteries that must maintain their capacity and reliability over hundreds of charging cycles in demanding conditions. Battery degradation is a critical concern, as it directly impacts vehicle range, payload capacity, and safety.\n",
    "\n",
    "Battery degradation is influenced by numerous factors including temperature fluctuations, charge/discharge rates, depth of discharge, and overall usage patterns. Predicting how a battery's discharge capacity will change over time is crucial for maintenance scheduling, fleet management, and ensuring safe operations.\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "In this RAMP challenge, you will develop models to predict battery degradation based on cycling data. You'll be provided with detailed measurements from battery cycles, including voltage curves, current profiles, temperature readings, and other key parameters. The goal is to predict the future discharge capacity of batteries as they age through multiple cycles.\n",
    "\n",
    "This challenge has important real-world implications: accurate prediction of battery degradation can improve safety margins, optimize maintenance schedules, and extend the useful life of expensive battery packs in the growing eVTOL industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Access to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/battery_features_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mproblem\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m X_df, y \u001b[38;5;241m=\u001b[39m \u001b[43mproblem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_train_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ENSTAParis/ENSTA/3A/datacamp/datacamp_project/problem.py:38\u001b[0m, in \u001b[0;36mget_train_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_train_data\u001b[39m(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get training data.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbattery_features_train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ENSTAParis/ENSTA/3A/datacamp/datacamp_project/problem.py:31\u001b[0m, in \u001b[0;36m_read_data\u001b[0;34m(path, filename)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_data\u001b[39m(path, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbattery_features.csv\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read and prepare training and testing data.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     y_array \u001b[38;5;241m=\u001b[39m data[_target_column_name]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     33\u001b[0m     X_df \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[_target_column_name])\n",
      "File \u001b[0;32m~/mambaforge/envs/ramp/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/ramp/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/mambaforge/envs/ramp/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/ramp/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/mambaforge/envs/ramp/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/battery_features_train.csv'"
     ]
    }
   ],
   "source": [
    "import problem\n",
    "\n",
    "X_df, y = problem.get_train_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Dataset\n",
    "\n",
    "Our dataset consists of measurements from multiple batteries at different points in their lifecycle. Each battery undergoes many charge and discharge cycles, with measurements taken throughout each cycle.\n",
    "\n",
    "Let's examine the structure of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset shape: {X_df.shape}\")\n",
    "print(f\"Number of unique batteries: {X_df['battery_id'].nunique()}\")\n",
    "print(f\"Cycles per battery: {X_df.groupby('battery_id')['cycle_number'].max().mean():.1f} (average)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Features\n",
    "\n",
    "Let's understand the key features in our dataset:\n",
    "\n",
    "- **battery_id**: Unique identifier for each battery\n",
    "- **cycle_number**: The sequence number of charge/discharge cycle\n",
    "- **charge_capacity**: The capacity measured during charging (mAh)\n",
    "- **discharge_capacity**: The capacity measured during discharging (mAh) - this is our target variable\n",
    "- **charge_time**: Duration of the charging phase (seconds)\n",
    "- **discharge_time**: Duration of the discharging phase (seconds)\n",
    "- **energy_efficiency**: Ratio of discharge energy to charge energy\n",
    "- **max_voltage**: Maximum cell voltage during the cycle (V)\n",
    "- **min_voltage**: Minimum cell voltage during the cycle (V)\n",
    "- **avg_temperature**: Average temperature during the cycle (°C)\n",
    "- **max_temperature**: Maximum temperature during the cycle (°C)\n",
    "- **voltage_drop_rate**: Rate of voltage decrease during discharge (V/s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capacity Degradation Over Cycles\n",
    "\n",
    "Let's examine how the discharge capacity of batteries degrades over multiple cycles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for battery_id in X_df['battery_id'].unique()[:5]:  # Plot first 5 batteries\n",
    "    battery_data = X_df[X_df['battery_id'] == battery_id]\n",
    "    plt.plot(battery_data['cycle_number'], battery_data['discharge_capacity'], \n",
    "             marker='o', markersize=4, linestyle='-', alpha=0.7, label=f'Battery {battery_id}')\n",
    "    \n",
    "plt.xlabel('Cycle Number', fontsize=12)\n",
    "plt.ylabel('Discharge Capacity (mAh)', fontsize=12)\n",
    "plt.title('Discharge Capacity vs. Cycle Number', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the characteristic capacity fade curve, where capacity decreases more rapidly in early cycles and then stabilizes into a more gradual decline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations Between Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "correlation_matrix = X_df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Feature Correlation Heatmap', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Voltage Curves\n",
    "\n",
    "Let's look at voltage profiles during discharge for a single battery at different points in its lifecycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_discharge_curves(battery_id, cycles_to_plot=None):\n",
    "    \"\"\"Plot discharge voltage curves for specified cycles of a battery\"\"\"\n",
    "    \n",
    "    # If no specific cycles requested, choose a representative sample\n",
    "    if cycles_to_plot is None:\n",
    "        battery_data = X_df[X_df['battery_id'] == battery_id]\n",
    "        total_cycles = battery_data['cycle_number'].max()\n",
    "        cycles_to_plot = [1, int(total_cycles*0.25), int(total_cycles*0.5), \n",
    "                           int(total_cycles*0.75), total_cycles]\n",
    "    \n",
    "    # Load the raw cycle data for this battery\n",
    "    # Note: In a real implementation, you'd load the actual voltage curves from files\n",
    "    # For this example, we'll simulate voltage curves\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Generate simulated discharge voltage curves for illustration\n",
    "    # (In practice, you'd load the actual data)\n",
    "    for cycle in cycles_to_plot:\n",
    "        # Get capacity for this cycle\n",
    "        cycle_data = X_df[(X_df['battery_id'] == battery_id) & \n",
    "                           (X_df['cycle_number'] == cycle)]\n",
    "        \n",
    "        if len(cycle_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Generate simulated discharge curve\n",
    "        # In real data, you'd have actual time series \n",
    "        capacity = cycle_data['discharge_capacity'].values[0]\n",
    "        max_v = cycle_data['max_voltage'].values[0]\n",
    "        min_v = cycle_data['min_voltage'].values[0]\n",
    "        \n",
    "        # Simulate a discharge curve\n",
    "        discharge_time = np.linspace(0, 1, 100)\n",
    "        # As batteries age, the voltage drops more quickly\n",
    "        curve_factor = 1 + (cycle/cycles_to_plot[-1])\n",
    "        voltage = max_v - (max_v-min_v) * np.power(discharge_time, 1/curve_factor)\n",
    "        \n",
    "        plt.plot(discharge_time, voltage, label=f'Cycle {cycle} - Cap: {capacity:.1f} mAh')\n",
    "    \n",
    "    plt.xlabel('Normalized Discharge Time', fontsize=12)\n",
    "    plt.ylabel('Cell Voltage (V)', fontsize=12)\n",
    "    plt.title(f'Battery {battery_id} Discharge Voltage Curves', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot discharge curves for a sample battery\n",
    "sample_battery_id = X_df['battery_id'].iloc[0]\n",
    "plot_discharge_curves(sample_battery_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As batteries degrade, their voltage drops more quickly during discharge. This change in the voltage curve shape is an important indicator of battery health."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature Effects on Degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create scatter plot with color based on temperature\n",
    "scatter = plt.scatter(X_df['cycle_number'], X_df['discharge_capacity'],\n",
    "                     c=X_df['avg_temperature'], alpha=0.6, cmap='viridis',\n",
    "                     s=30, edgecolors='none')\n",
    "\n",
    "plt.colorbar(scatter, label='Average Temperature (°C)')\n",
    "plt.xlabel('Cycle Number', fontsize=12)\n",
    "plt.ylabel('Discharge Capacity (mAh)', fontsize=12)\n",
    "plt.title('Discharge Capacity vs. Cycle Number (colored by temperature)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capacity vs. Energy Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_df['energy_efficiency'], X_df['discharge_capacity'], \n",
    "            alpha=0.5, c=X_df['cycle_number'], cmap='coolwarm')\n",
    "\n",
    "plt.colorbar(label='Cycle Number')\n",
    "plt.xlabel('Energy Efficiency', fontsize=12)\n",
    "plt.ylabel('Discharge Capacity (mAh)', fontsize=12)\n",
    "plt.title('Discharge Capacity vs. Energy Efficiency', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Let's develop some features that might be useful for predicting battery degradation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"Create derived features that might help with degradation prediction\"\"\"\n",
    "    \n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Calculate capacity retention as percentage of initial capacity\n",
    "    for battery_id in df['battery_id'].unique():\n",
    "        battery_data = df[df['battery_id'] == battery_id]\n",
    "        initial_capacity = battery_data[battery_data['cycle_number'] == \n",
    "                                      battery_data['cycle_number'].min()]['discharge_capacity'].values[0]\n",
    "        df.loc[df['battery_id'] == battery_id, 'capacity_retention'] = \\\n",
    "            df.loc[df['battery_id'] == battery_id, 'discharge_capacity'] / initial_capacity\n",
    "    \n",
    "    # Calculate differential features\n",
    "    for battery_id in df['battery_id'].unique():\n",
    "        battery_data = df[df['battery_id'] == battery_id].sort_values('cycle_number')\n",
    "        \n",
    "        # Calculate capacity change rate (per cycle)\n",
    "        capacity_change = battery_data['discharge_capacity'].diff() / battery_data['cycle_number'].diff()\n",
    "        df.loc[battery_data.index, 'capacity_change_rate'] = capacity_change\n",
    "        \n",
    "        # Calculate voltage efficiency (min/max ratio)\n",
    "        df.loc[battery_data.index, 'voltage_efficiency'] = \\\n",
    "            battery_data['min_voltage'] / battery_data['max_voltage']\n",
    "        \n",
    "        # Moving averages\n",
    "        df.loc[battery_data.index, 'discharge_capacity_ma3'] = \\\n",
    "            battery_data['discharge_capacity'].rolling(3, min_periods=1).mean()\n",
    "    \n",
    "    # Calculate temperature variation\n",
    "    df['temp_variation'] = df['max_temperature'] - df['avg_temperature']\n",
    "    \n",
    "    # Add polynomial features for cycle number\n",
    "    df['cycle_number_squared'] = df['cycle_number'] ** 2\n",
    "    df['cycle_number_cubed'] = df['cycle_number'] ** 3\n",
    "    df['log_cycle_number'] = np.log1p(df['cycle_number'])\n",
    "    \n",
    "    # Add interaction features\n",
    "    df['temp_cycle_interaction'] = df['avg_temperature'] * df['cycle_number']\n",
    "    df['charge_time_efficiency'] = df['charge_time'] / df['energy_efficiency']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create engineered features\n",
    "X_df_engineered = engineer_features(X_df)\n",
    "\n",
    "# Check the new features\n",
    "new_features = [col for col in X_df_engineered.columns if col not in X_df.columns]\n",
    "print(f\"Newly created features: {new_features}\")\n",
    "X_df_engineered[['cycle_number', 'discharge_capacity'] + new_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Derived Features\n",
    "\n",
    "Let's examine how some of these engineered features relate to the battery degradation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for battery_id in X_df_engineered['battery_id'].unique()[:5]:  # Plot first 5 batteries\n",
    "    battery_data = X_df_engineered[X_df_engineered['battery_id'] == battery_id]\n",
    "    plt.plot(battery_data['cycle_number'], battery_data['capacity_retention'], \n",
    "             marker='o', markersize=4, linestyle='-', alpha=0.7, label=f'Battery {battery_id}')\n",
    "    \n",
    "plt.xlabel('Cycle Number', fontsize=12)\n",
    "plt.ylabel('Capacity Retention (fraction of initial)', fontsize=12)\n",
    "plt.title('Capacity Retention vs. Cycle Number', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_df_engineered['capacity_change_rate'], X_df_engineered['discharge_capacity'], \n",
    "            alpha=0.5, c=X_df_engineered['cycle_number'], cmap='viridis')\n",
    "plt.colorbar(label='Cycle Number')\n",
    "plt.xlabel('Capacity Change Rate', fontsize=11)\n",
    "plt.ylabel('Discharge Capacity (mAh)', fontsize=11)\n",
    "plt.title('Discharge Capacity vs. Capacity Change Rate', fontsize=13)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_df_engineered['voltage_efficiency'], X_df_engineered['discharge_capacity'], \n",
    "            alpha=0.5, c=X_df_engineered['cycle_number'], cmap='viridis')\n",
    "plt.colorbar(label='Cycle Number')\n",
    "plt.xlabel('Voltage Efficiency (min/max)', fontsize=11)\n",
    "plt.ylabel('Discharge Capacity (mAh)', fontsize=11)\n",
    "plt.title('Discharge Capacity vs. Voltage Efficiency', fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Baseline Model\n",
    "\n",
    "Let's create a simple baseline regression model to predict discharge capacity using our engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Select features to use in the model\n",
    "features = [\n",
    "    'cycle_number', 'charge_capacity', 'energy_efficiency',\n",
    "    'max_voltage', 'min_voltage', 'avg_temperature',\n",
    "    'charge_time', 'discharge_time', 'voltage_drop_rate',\n",
    "    # Engineered features\n",
    "    'capacity_retention', 'voltage_efficiency', 'temp_variation',\n",
    "    'cycle_number_squared', 'log_cycle_number', 'temp_cycle_interaction'\n",
    "]\n",
    "\n",
    "# Ensure all selected features are in the dataframe\n",
    "available_features = [f for f in features if f in X_df_engineered.columns]\n",
    "print(f\"Using {len(available_features)} features: {available_features}\")\n",
    "\n",
    "# Prepare the data\n",
    "X = X_df_engineered[available_features].fillna(0)  # Simple handling of missing values\n",
    "y = X_df_engineered['discharge_capacity']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a random forest model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f} mAh\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "# Plot predicted vs actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Discharge Capacity (mAh)', fontsize=12)\n",
    "plt.ylabel('Predicted Discharge Capacity (mAh)', fontsize=12)\n",
    "plt.title('Random Forest: Actual vs Predicted Discharge Capacity', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': available_features,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
    "plt.title('Feature Importance for Discharge Capacity Prediction', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis\n",
    "\n",
    "Since battery degradation is a time series problem (sequences of cycles), let's look at approaches that consider the sequential nature of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create lagged features for time series prediction\n",
    "def create_lagged_features(df, lag_features, lags):\n",
    "    \"\"\"Create lagged features for time series prediction\"\"\"\n",
    "    df_with_lags = df.copy()\n",
    "    \n",
    "    # For each battery, create lagged features\n",
    "    for battery_id in df['battery_id'].unique():\n",
    "        battery_data = df[df['battery_id'] == battery_id].sort_values('cycle_number')\n",
    "        \n",
    "        for feature in lag_features:\n",
    "            for lag in lags:\n",
    "                # Create the lagged feature\n",
    "                lagged_values = battery_data[feature].shift(lag)\n",
    "                df_with_lags.loc[battery_data.index, f\"{feature}_lag{lag}\"] = lagged_values\n",
    "    \n",
    "    return df_with_lags\n",
    "\n",
    "# Create lagged features for important predictors\n",
    "lag_features = ['discharge_capacity', 'charge_capacity', 'energy_efficiency']\n",
    "lags = [1, 2, 3]  # Previous cycles\n",
    "\n",
    "X_df_with_lags = create_lagged_features(X_df_engineered, lag_features, lags)\n",
    "\n",
    "# Show the lagged features for the first few rows\n",
    "lag_cols = [col for col in X_df_with_lags.columns if 'lag' in col]\n",
    "print(f\"Created {len(lag_cols)} lagged features: {lag_cols}\")\n",
    "X_df_with_lags[['battery_id', 'cycle_number', 'discharge_capacity'] + lag_cols].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Final Model\n",
    "\n",
    "Now let's integrate the feature engineering and modeling steps into a complete pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Define the feature engineering function\n",
    "def battery_feature_engineering(X):\n",
    "    \"\"\"Create features for battery degradation prediction\"\"\"\n",
    "    # Ensure it's a DataFrame\n",
    "    X = pd.DataFrame(X) if not isinstance(X, pd.DataFrame) else X.copy()\n",
    "    \n",
    "    # Basic features\n",
    "    if 'voltage_efficiency' not in X.columns and 'min_voltage' in X.columns and 'max_voltage' in X.columns:\n",
    "        X['voltage_efficiency'] = X['min_voltage'] / X['max_voltage']\n",
    "    \n",
    "    if 'temp_variation' not in X.columns and 'max_temperature' in X.columns and 'avg_temperature' in X.columns:\n",
    "        X['temp_variation'] = X['max_temperature'] - X['avg_temperature']\n",
    "        \n",
    "    if 'cycle_squared' not in X.columns and 'cycle_number' in X.columns:\n",
    "        X['cycle_squared'] = X['cycle_number'] ** 2\n",
    "        X['log_cycle'] = np.log1p(X['cycle_number'])\n",
    "        \n",
    "    # Calculate time-based features if available\n",
    "    if 'charge_time' in X.columns and 'discharge_time' in X.columns:\n",
    "        X['total_cycle_time'] = X['charge_time'] + X['discharge_time']\n",
    "        X['charge_discharge_ratio'] = X['charge_time'] / X['discharge_time']\n",
    "    \n",
    "    return X\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "def get_preprocessing_pipeline():\n",
    "    numeric_features = [\n",
    "        'charge_capacity', 'energy_efficiency', 'voltage_drop_rate',\n",
    "        'avg_temperature', 'max_temperature', 'max_voltage', 'min_voltage', \n",
    "        'charge_time', 'discharge_time', 'cycle_number'\n",
    "    ]\n",
    "    \n",
    "    # Feature engineering\n",
    "    feature_engineering = FunctionTransformer(battery_feature_engineering)\n",
    "    \n",
    "    # Preprocessing for numerical features\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    # Bundle preprocessing steps\n",
    "    preprocessor = Pipeline(steps=[\n",
    "        ('feature_eng', feature_engineering),\n",
    "        ('column_trans', ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numeric_transformer, numeric_features)\n",
    "            ],\n",
    "            remainder='passthrough'\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "# Create the full model pipeline\n",
    "def build_model(model_type='rf'):\n",
    "    preprocessor = get_preprocessing_pipeline()\n",
    "    \n",
    "    if model_type == 'rf':\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=15,\n",
    "            min_samples_split=5,\n",
    "            random_state=42\n",
    "        )\n",
    "    elif model_type == 'gbm':\n",
    "        model = GradientBoostingRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=5,\n",
    "            random_state=42\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    # Create full pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "def evaluate_model(pipeline, X_train, y_train, X_test, y_test):\n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    \n",
    "    # Plot actual vs predicted\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
    "    plt.xlabel('Actual Capacity')\n",
    "    plt.ylabel('Predicted Capacity')\n",
    "    plt.title('Actual vs Predicted Battery Capacity')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "def feature_importance_analysis(pipeline, X):\n",
    "    # Convert input data through preprocessing\n",
    "    X_processed = pipeline.named_steps['preprocessor'].transform(X)\n",
    "    \n",
    "    # Get feature names\n",
    "    feature_names = list(X.columns)\n",
    "    \n",
    "    # Get feature importances (works for tree-based models)\n",
    "    if hasattr(pipeline.named_steps['model'], 'feature_importances_'):\n",
    "        importances = pipeline.named_steps['model'].feature_importances_\n",
    "        \n",
    "        # Sort feature importances\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        # Print feature ranking\n",
    "        print(\"Feature ranking:\")\n",
    "        for f in range(min(10, X_processed.shape[1])):  # Show top 10 features\n",
    "            print(f\"{f+1}. {feature_names[indices[f]]} ({importances[indices[f]]:.4f})\")\n",
    "        \n",
    "        # Plot feature importances\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.title(\"Feature importances\")\n",
    "        plt.bar(range(min(10, X_processed.shape[1])), \n",
    "                importances[indices[:10]],\n",
    "                align=\"center\")\n",
    "        plt.xticks(range(min(10, X_processed.shape[1])), \n",
    "                  [feature_names[i] for i in indices[:10]], \n",
    "                  rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a submission\n",
    "def create_submission(pipeline, X_test, output_file='submission.csv'):\n",
    "    # Make predictions on test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Create submission DataFrame\n",
    "    submission = pd.DataFrame({\n",
    "        'battery_id': X_test['battery_id'] if 'battery_id' in X_test.columns else range(len(X_test)),\n",
    "        'cycle_number': X_test['cycle_number'],\n",
    "        'predicted_capacity': y_pred\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    submission.to_csv(output_file, index=False)\n",
    "    print(f\"Submission saved to {output_file}\")\n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample workflow\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load train/test data\n",
    "    from problem import get_train_data, get_test_data\n",
    "    \n",
    "    X_train, y_train = get_train_data()\n",
    "    X_test, _ = get_test_data()  # y_test would be None for the actual submission\n",
    "    \n",
    "    # 2. Split training data for local validation\n",
    "    X_train_local, X_val, y_train_local, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # 3. Build and train model\n",
    "    model_pipeline = build_model(model_type='rf')\n",
    "    \n",
    "    # 4. Evaluate model\n",
    "    rmse, r2 = evaluate_model(model_pipeline, X_train_local, y_train_local, X_val, y_val)\n",
    "    \n",
    "    # 5. Train on full training set\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # 6. Feature importance analysis\n",
    "    feature_importance_analysis(model_pipeline, X_train)\n",
    "    \n",
    "    # 7. Create submission file\n",
    "    submission = create_submission(model_pipeline, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation performance\n",
    "def cv_performance(pipeline, X, y, cv=5):\n",
    "    # Get cross-validation scores\n",
    "    cv_rmse = -cross_val_score(\n",
    "        pipeline, X, y, \n",
    "        cv=cv, \n",
    "        scoring='neg_root_mean_squared_error'\n",
    "    )\n",
    "    \n",
    "    cv_r2 = cross_val_score(\n",
    "        pipeline, X, y, \n",
    "        cv=cv, \n",
    "        scoring='r2'\n",
    "    )\n",
    "    \n",
    "    print(f\"CV RMSE: {cv_rmse.mean():.4f} (±{cv_rmse.std():.4f})\")\n",
    "    print(f\"CV R²: {cv_r2.mean():.4f} (±{cv_r2.std():.4f})\")\n",
    "    \n",
    "    return cv_rmse, cv_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "def tune_hyperparameters(X, y):\n",
    "    # Define the preprocessing pipeline\n",
    "    preprocessor = get_preprocessing_pipeline()\n",
    "    \n",
    "    # Define the model\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    \n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'model__n_estimators': [50, 100, 200],\n",
    "        'model__max_depth': [10, 15, 20],\n",
    "        'model__min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    \n",
    "    # Create the full pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Create GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, param_grid, cv=5,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1, verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit the grid search\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    # Print the best parameters\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best RMSE: {-grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Return the best model\n",
    "    return grid_search.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ramp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
